{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Character Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources = {\n",
    "    \"training_images\": \"train-images.idx3-ubyte\",  # 60,000 training images\n",
    "    \"test_images\": \"t10k-images.idx3-ubyte\",       # 10,000 test images\n",
    "    \"training_labels\": \"train-labels.idx1-ubyte\",  # 60,000 training labels\n",
    "    \"test_labels\": \"t10k-labels.idx1-ubyte\",       # 10,000 test labels\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist: dict[str, np.ndarray] = {}\n",
    "\n",
    "for key in (\"training_images\", \"test_images\"):\n",
    "    with open(f'data/{data_sources[key]}', \"rb\") as mnist_dataset:\n",
    "        mnist[key] = np.frombuffer(\n",
    "            mnist_dataset.read(), np.uint8, offset=16\n",
    "        ).reshape(-1, 28 * 28)\n",
    "\n",
    "for key in (\"training_labels\", \"test_labels\"):\n",
    "    with open(f'data/{data_sources[key]}', \"rb\") as mnist_dataset:\n",
    "        mnist[key] = np.frombuffer(\n",
    "            mnist_dataset.read(), np.uint8, offset=8)\n",
    "print(mnist['training_images'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = (\n",
    "    mnist[\"training_images\"],\n",
    "    mnist[\"training_labels\"],\n",
    "    mnist[\"test_images\"],\n",
    "    mnist[\"test_labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of training images is {x_train.shape} and training labels is {y_train.shape}\")\n",
    "print(f\"Shape of test images is {x_test.shape} and test labels is {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 5 random images from the training set.\n",
    "num_examples = 5\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "fig, all_axes = plt.subplots(1, num_examples)\n",
    "for sample, ax in zip(rng.choice(x_train, size=num_examples, replace=False), all_axes):\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.imshow(sample.reshape(28, 28), cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:06:05.528479 [INFO]:  Network Created\n",
      "01:06:28.732463 [INFO]:  Epoch 10: Error=0.125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\Personal\\neural_network\\main.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Personal/neural_network/main.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m train_x, test_x, train_y, test_y \u001b[39m=\u001b[39m train_test_split(x, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Personal/neural_network/main.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m nn \u001b[39m=\u001b[39m Network(layers\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m18\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m2\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Personal/neural_network/main.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m              activations\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/Personal/neural_network/main.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m nn\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49mtrain_x, labels\u001b[39m=\u001b[39;49mtrain_y, loss_function\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mMSE\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Personal/neural_network/main.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m          epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Personal/neural_network/main.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m TOTAL_SAMPLES \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/Personal/neural_network/main.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mD:\\Projects\\Personal\\neural_network\\neural_network.py:194\u001b[0m, in \u001b[0;36mNetwork.train\u001b[1;34m(self, data, labels, epochs, loss_function, learning_rate, momentum)\u001b[0m\n\u001b[0;32m    192\u001b[0m epoch_error: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    193\u001b[0m \u001b[39mfor\u001b[39;00m data_index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data)):\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49massign_input(data[data_index])\n\u001b[0;32m    196\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_pass()\n\u001b[0;32m    197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_pass(targets\u001b[39m=\u001b[39mlabels[data_index],\n\u001b[0;32m    198\u001b[0m                        loss_function\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function,\n\u001b[0;32m    199\u001b[0m                        loss_derivative\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_derivative,\n\u001b[0;32m    200\u001b[0m                        learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[0;32m    201\u001b[0m                        momentum\u001b[39m=\u001b[39mmomentum)\n",
      "File \u001b[1;32mD:\\Projects\\Personal\\neural_network\\neural_network.py:93\u001b[0m, in \u001b[0;36mLayer.assign_input\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39massign_input\u001b[39m(\u001b[39mself\u001b[39m, inputs: npt\u001b[39m.\u001b[39mNDArray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[39mfor\u001b[39;00m index, neuron \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurons):\n\u001b[1;32m---> 93\u001b[0m         neuron\u001b[39m.\u001b[39mactivation \u001b[39m=\u001b[39m neuron\u001b[39m.\u001b[39;49mactivation_function(inputs[index])\n",
      "File \u001b[1;32mD:\\Projects\\Personal\\neural_network\\functions.py:19\u001b[0m, in \u001b[0;36mActivations.sigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m (x \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m*\u001b[39m x\n\u001b[0;32m     14\u001b[0m \u001b[39m# @staticmethod\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# def softmax(x: float) -> float:\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m#     return (exp(x - 1) /\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m#             np.sum(exp(x - 1)))\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msigmoid\u001b[39m(x: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m exp(\u001b[39m-\u001b[39mx))\n\u001b[0;32m     23\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtanh\u001b[39m(x: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from neural_network import Network\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "p = np.random.permutation(x.shape[0])\n",
    "x = x[p]\n",
    "y = y[p]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "nn = Network(layers=(30, 18, 8, 2),\n",
    "             activations=['sigmoid', 'relu', 'sigmoid'])\n",
    "\n",
    "\n",
    "nn.train(data=train_x, labels=train_y, loss_function='MSE',\n",
    "         epochs=200, learning_rate=0.001)\n",
    "\n",
    "TOTAL_SAMPLES = 10\n",
    "correct = 0\n",
    "\n",
    "for _ in range(TOTAL_SAMPLES):\n",
    "    random_sample = int(x.shape[0] * (np.random.random()))\n",
    "    prediction = nn.predict(x[random_sample])\n",
    "    answer = y[random_sample]\n",
    "    # print(f'{answer} -> {prediction}')\n",
    "    if int(prediction) == int(answer):\n",
    "        correct += 1\n",
    "print(f'Accuracy: {correct} out of {TOTAL_SAMPLES}')\n",
    "\n",
    "correct = 0\n",
    "actual = []\n",
    "output = []\n",
    "for test_index in range(test_y.shape[0]):\n",
    "    prediction = nn.predict(test_x[test_index])\n",
    "    answer = y[test_index]\n",
    "    output.append(prediction)\n",
    "    actual.append(answer)\n",
    "    print(f'{answer} -> {prediction}')\n",
    "    if int(prediction) == int(answer) and answer != 0:\n",
    "        correct += 1\n",
    "print(f'Accuracy: {correct} out of {test_y.shape[0]}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(nn.total_error)\n",
    "plt.show()\n",
    "\n",
    "plt.title('output')\n",
    "plt.scatter(actual, output)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
